# AR Project Documentation

## Overview
This AR (Augmented Reality) project is a web-based application that uses face tracking to apply various filters and effects in real-time. The project uses MediaPipe's Face Mesh for accurate facial landmark detection and provides an interactive experience with music, sound effects, and visual filters.

## Features

### Core Features
- Real-time face tracking and filter application
- Camera controls (front/back camera toggle)
- Photo capture functionality
- Background music with toggle control
- Interactive sound effects (meow sound on mouth opening)

### Visual Effects
- Cat filter with:
  - Animated ears
  - Tracking eyes
  - Whiskers
  - Nose
- Jewel necklace effect
- Particle effects and animations

## Technical Requirements

### Browser Support
- Chrome (recommended)
- Firefox
- Safari
- Edge

### Hardware Requirements
- Webcam or mobile device camera
- Microphone (for sound effects)
- Speakers or headphones

## Setup and Installation

1. Clone the repository:
```bash
git clone [repository-url]
```

2. Navigate to the project directory:
```bash
cd AR_project
```

3. Open `index.html` in a web browser
   - For best results, use a local server (e.g., Live Server in VS Code)

## Usage Guide

### Starting the AR Experience
1. Click the "Start AR Experience" button
2. Grant camera permissions when prompted
3. Position yourself 2-3 feet from the camera
4. Ensure good lighting for optimal face tracking

### Controls
- **Start AR Experience**: Initiates the AR session
- **Exit AR**: Ends the AR session
- **Music Toggle (ðŸ”Š)**: Controls background music
- **Camera Toggle (ðŸ”„)**: Switches between front and back cameras
- **Photo Capture (ðŸ“¸)**: Takes a screenshot of the current view

### Interactive Features
- **Mouth Opening**: Opening your mouth triggers a meow sound effect
- **Face Tracking**: The cat filter follows your facial movements
- **Animated Elements**: Ears wiggle and whiskers move for added realism

## File Structure
```
AR_project/
â”œâ”€â”€ index.html          # Main HTML file
â”œâ”€â”€ styles.css          # CSS styles
â”œâ”€â”€ ar.js              # Main JavaScript file
â””â”€â”€ README.md          # Documentation
```

## Dependencies
- MediaPipe Face Mesh
- MediaPipe Camera Utils

## Technical Implementation

### Face Tracking
The application uses MediaPipe's Face Mesh to detect 468 facial landmarks, enabling precise filter placement and tracking.

### Sound Implementation
- Background music loops continuously
- Meow sound triggers on mouth opening detection
- Sound cooldown prevents rapid-fire triggering

### Performance Considerations
- Canvas-based rendering for optimal performance
- Efficient face tracking with configurable confidence thresholds
- Responsive design for various screen sizes

## Troubleshooting

### Common Issues
1. **Camera Not Working**
   - Check browser permissions
   - Ensure no other applications are using the camera
   - Try refreshing the page

2. **Poor Face Tracking**
   - Improve lighting conditions
   - Adjust distance from camera
   - Ensure face is clearly visible

3. **Sound Issues**
   - Check browser sound permissions
   - Ensure device is not muted
   - Try using a different browser

## Contributing
Feel free to contribute to this project by:
1. Forking the repository
2. Creating a feature branch
3. Submitting a pull request

## License
[Specify your license here]

## Contact
[Your contact information] 